# **Finding Lane Lines on the Road**

## Writeup

---

**Finding Lane Lines on the Road**

The goals / steps of this project are the following:

* Make a pipeline that finds lane lines on the road
* Reflect on your work in a written report


[//]: # (Image References)

[Pipeline]: ./pipeline.png "Pipeline"

[solidWhiteCurve]: ./test_images_output/solidWhiteCurve.jpg "solidWhiteCurve"

[solidWhiteRight]: ./test_images_output/solidWhiteRight.jpg "solidWhiteRight"

[solidYellowCurve]: ./test_images_output/solidYellowCurve.jpg "solidYellowCurve"

[solidYellowCurve2]: ./test_images_output/solidYellowCurve2.jpg "solidYellowCurve2"

[solidYellowLeft]: ./test_images_output/solidYellowLeft.jpg "solidYellowLeft"

[whiteCarLaneSwitch]: ./test_images_output/whiteCarLaneSwitch.jpg "whiteCarLaneSwitch"

---

### System setup

The project uses the [carnd-term1](https://github.com/udacity/CarND-Term1-Starter-Kit) conda environment with additionally installed Graphviz and nxpd. These components can be installed via:

```
conda install graphviz
pip install graphviz pygraphviz nxpd
```

### Pipeline description

The pipeline for lane detection was built upon the computational graph implementation from the [EPypes project](https://github.com/semeniuta/EPypes). The idea is that you create a library of Python functions for certain application-specific computations, and later declaratively combine them into a directed acyclic graph. The latter can be run once its topological sort is performed. The graph can also be visualized with Graphviz. It is bipartite: the functions are shown as rectangles, and the data tokens -- as ellipses. The shaded ellipses correspond to *frozen* tokens, i.e. source tokens with fixed values. They represent tuned parameters of a vision algorithm.

The core functions used in the developed pipeline reside in the `lanelines.py` Python module, while the original Udacity helper functions are decomposed into `udacityhelpers.py`. The computational graph for the lane detection pipeline is defined in `lanespipeline.py`. Its visualization is shown below:

![alt text][Pipeline]

The original RGB image is grayscaled, and smoothed with a Gaussian kernel. A region mask is applied to the smoothed image, where the region of interest polygon is defined for a particular camera setup (`define_lanes_region`). Having a masked image, Hough transform is applied for find line segments, which are later extrapolated to the top and bottom of the region of interest (`extend_lines`). When extrapolating, line segments with too small slope (hence, close to horizontal) are eliminated. The extrapolated line segments are grouped by their slopes into those corresponding to the left lane and the right lane. Both groups are then averaged to return a single pair of line segments that can be drawn on the test images and video frames.

Dealing with the computational graph and its integration into media files generations is simplified with the `LaneFinder` class and the generated `find_and_draw_lanes` closure function (both in `lanefinder.py`).

All the resulting media files are generated by the `genmedia.py` script.

The result of applying the developed lane detection pipeline to the test images is shown below:

![alt text][solidWhiteCurve]

![alt text][solidWhiteRight]

![alt text][solidYellowCurve]

![alt text][solidYellowCurve2]

![alt text][solidYellowLeft]

![alt text][whiteCarLaneSwitch]

The resulting videos (`solidWhiteRight.mp4` and `solidYellowLeft.mp4`) reside in the `test_videos_output` directory.

An alternative, though not used, pipeline is defined in `lanespipeline-weighted-avg.py`. It uses distance of the largest y-coordinate of a line segment to the bottom of the image to weight its contribution to the averaged line segment.

### Pipeline shortcomings and possible improvements

The biggest shortcoming of the developed pipeline is in its tight reliance on the tuned values of the algorithms' parameters. The functionality can break if a variation of colors occur, e.g. when the road color becomes darker or brighter. In addition, in all the test cases, the region of interest in front of the car is not occluded. In the latter happens, however, the outcomes of the algorithm may be wrong (a possible scenario is when another car in front is changing lanes).  

One way of improvement of the pipeline is in addressing the probable appearance changing events by incorporating additional logic. A similar approach is a built-in appearance detection scheme on the real-time level, which will tune the algorithm parameters accordingly. A more sophisticated semantic segmentation method can also be incorporated, where pixel regions corresponding to the road, the lane lines, the vehicles, the pedestrians, etc, could be identified. Such a segmentation function could be learned from data by application of a suitable machine learning algorithm.
